//
// Generated by NVIDIA NVVM Compiler
//
// Compiler Build ID: CL-34097967
// Cuda compilation tools, release 12.4, V12.4.131
// Based on NVVM 7.0.1
//

.version 8.4
.target sm_80
.address_size 64

	// .globl	_Z9testcopy2PfS_i
.extern .func  (.param .b32 func_retval0) vprintf
(
	.param .b64 vprintf_param_0,
	.param .b64 vprintf_param_1
)
;
// _ZZ9testcopy2PfS_iE7barrier has been demoted
.extern .shared .align 16 .b8 shared[];
.global .align 1 .b8 $str[4] = {37, 102, 32};

.visible .entry _Z9testcopy2PfS_i(
	.param .u64 _Z9testcopy2PfS_i_param_0,
	.param .u64 _Z9testcopy2PfS_i_param_1,
	.param .u32 _Z9testcopy2PfS_i_param_2
)
{
	.local .align 8 .b8 	__local_depot0[8];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<17>;
	.reg .f32 	%f<2>;
	.reg .b32 	%r<50>;
	.reg .f64 	%fd<2>;
	.reg .b64 	%rd<48>;
	// demoted variable
	.shared .align 8 .b8 _ZZ9testcopy2PfS_iE7barrier[8];

	mov.u64 	%SPL, __local_depot0;
	cvta.local.u64 	%SP, %SPL;
	ld.param.u64 	%rd17, [_Z9testcopy2PfS_i_param_0];
	ld.param.u64 	%rd18, [_Z9testcopy2PfS_i_param_1];
	ld.param.u32 	%r15, [_Z9testcopy2PfS_i_param_2];
	mov.u32 	%r1, %ntid.y;
	mov.u32 	%r16, %tid.z;
	mov.u32 	%r17, %tid.y;
	mad.lo.s32 	%r18, %r1, %r16, %r17;
	mov.u32 	%r2, %ntid.x;
	mov.u32 	%r19, %tid.x;
	mad.lo.s32 	%r3, %r18, %r2, %r19;
	setp.ne.s32 	%p1, %r3, 0;
	@%p1 bra 	$L__BB0_2;

	mul.lo.s32 	%r22, %r2, %r1;
	mov.u32 	%r23, %ntid.z;
	mul.lo.s32 	%r21, %r22, %r23;
	mov.u32 	%r20, _ZZ9testcopy2PfS_iE7barrier;
	// begin inline asm
	mbarrier.init.shared.b64 [%r20], %r21;
	// end inline asm

$L__BB0_2:
	barrier.sync 	0;
	setp.eq.s32 	%p2, %r15, 0;
	@%p2 bra 	$L__BB0_17;

	mul.lo.s32 	%r24, %r2, %r1;
	mov.u32 	%r25, %ntid.z;
	mul.lo.s32 	%r26, %r24, %r25;
	cvt.u64.u32 	%rd1, %r26;
	shl.b32 	%r4, %r26, 2;
	shl.b32 	%r5, %r3, 2;
	cvta.to.global.u64 	%rd2, %rd17;
	mov.u32 	%r27, shared;
	add.s32 	%r6, %r27, %r4;
	cvta.to.global.u64 	%rd3, %rd18;
	add.u64 	%rd21, %SP, 0;
	add.u64 	%rd4, %SPL, 0;
	cvt.s64.s32 	%rd5, %r15;
	mov.u64 	%rd47, 0;

$L__BB0_4:
	mul.lo.s64 	%rd7, %rd47, %rd1;
	setp.ge.s32 	%p3, %r5, %r4;
	@%p3 bra 	$L__BB0_7;

	shl.b64 	%rd22, %rd7, 2;
	add.s64 	%rd8, %rd2, %rd22;
	mov.u32 	%r46, %r5;

$L__BB0_6:
	add.s32 	%r28, %r27, %r46;
	cvt.s64.s32 	%rd24, %r46;
	add.s64 	%rd23, %rd8, %rd24;
	// begin inline asm
	cp.async.ca.shared.global [%r28], [%rd23], 4, 4;
	// end inline asm
	add.s32 	%r46, %r46, %r4;
	setp.lt.s32 	%p4, %r46, %r4;
	@%p4 bra 	$L__BB0_6;

$L__BB0_7:
	mov.u32 	%r30, _ZZ9testcopy2PfS_iE7barrier;
	// begin inline asm
	cp.async.mbarrier.arrive.shared.b64 [%r30];
	// end inline asm
	@%p3 bra 	$L__BB0_10;

	shl.b64 	%rd25, %rd7, 2;
	add.s64 	%rd9, %rd3, %rd25;
	mov.u32 	%r47, %r5;

$L__BB0_9:
	add.s32 	%r31, %r6, %r47;
	cvt.s64.s32 	%rd27, %r47;
	add.s64 	%rd26, %rd9, %rd27;
	// begin inline asm
	cp.async.ca.shared.global [%r31], [%rd26], 4, 4;
	// end inline asm
	add.s32 	%r47, %r47, %r4;
	setp.lt.s32 	%p6, %r47, %r4;
	@%p6 bra 	$L__BB0_9;

$L__BB0_10:
	// begin inline asm
	cp.async.mbarrier.arrive.shared.b64 [%r30];
	// end inline asm
	// begin inline asm
	mbarrier.arrive.shared.b64                                  %rd28,  [%r30];           // 1. 
	// end inline asm
	// begin inline asm
	mov.u64 %rd29, %globaltimer;
	// end inline asm
	mov.u32 	%r48, 0;
	bra.uni 	$L__BB0_11;

$L__BB0_29:
	add.s32 	%r48, %r48, 1;

$L__BB0_11:
	// begin inline asm
	{
	.reg .pred p;
	mbarrier.test_wait.shared.b64 p, [%r30], %rd28;
	selp.b32 %r35, 1, 0, p;
	}
	// end inline asm
	setp.eq.s32 	%p7, %r35, 0;
	@%p7 bra 	$L__BB0_24;
	bra.uni 	$L__BB0_12;

$L__BB0_24:
	setp.lt.s32 	%p14, %r48, 16;
	@%p14 bra 	$L__BB0_29;

	// begin inline asm
	mov.u64 %rd42, %globaltimer;
	// end inline asm
	sub.s64 	%rd16, %rd42, %rd29;
	setp.lt.s64 	%p15, %rd16, 4000000;
	@%p15 bra 	$L__BB0_27;
	bra.uni 	$L__BB0_26;

$L__BB0_27:
	setp.lt.s64 	%p16, %rd16, 40000;
	@%p16 bra 	$L__BB0_11;

	shr.s64 	%rd43, %rd16, 63;
	shr.u64 	%rd44, %rd43, 62;
	add.s64 	%rd45, %rd16, %rd44;
	shr.u64 	%rd46, %rd45, 2;
	cvt.u32.u64 	%r45, %rd46;
	// begin inline asm
	nanosleep.u32 %r45;
	// end inline asm
	bra.uni 	$L__BB0_11;

$L__BB0_26:
	mov.u32 	%r44, 1000000;
	// begin inline asm
	nanosleep.u32 %r44;
	// end inline asm
	bra.uni 	$L__BB0_11;

$L__BB0_12:
	@%p1 bra 	$L__BB0_14;

	ld.shared.f32 	%f1, [shared];
	cvt.f64.f32 	%fd1, %f1;
	st.local.f64 	[%rd4], %fd1;
	mov.u64 	%rd31, $str;
	cvta.global.u64 	%rd32, %rd31;
	{ // callseq 0, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd32;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd21;
	.param .b32 retval0;
	call.uni (retval0), 
	vprintf, 
	(
	param0, 
	param1
	);
	ld.param.b32 	%r37, [retval0+0];
	} // callseq 0

$L__BB0_14:
	// begin inline asm
	mbarrier.arrive.shared.b64                                  %rd34,  [%r30];           // 1. 
	// end inline asm
	// begin inline asm
	mov.u64 %rd35, %globaltimer;
	// end inline asm
	mov.u32 	%r49, 0;
	bra.uni 	$L__BB0_15;

$L__BB0_23:
	add.s32 	%r49, %r49, 1;

$L__BB0_15:
	// begin inline asm
	{
	.reg .pred p;
	mbarrier.test_wait.shared.b64 p, [%r30], %rd34;
	selp.b32 %r40, 1, 0, p;
	}
	// end inline asm
	setp.eq.s32 	%p9, %r40, 0;
	@%p9 bra 	$L__BB0_18;
	bra.uni 	$L__BB0_16;

$L__BB0_18:
	setp.lt.s32 	%p11, %r49, 16;
	@%p11 bra 	$L__BB0_23;

	// begin inline asm
	mov.u64 %rd37, %globaltimer;
	// end inline asm
	sub.s64 	%rd15, %rd37, %rd35;
	setp.lt.s64 	%p12, %rd15, 4000000;
	@%p12 bra 	$L__BB0_21;
	bra.uni 	$L__BB0_20;

$L__BB0_21:
	setp.lt.s64 	%p13, %rd15, 40000;
	@%p13 bra 	$L__BB0_15;

	shr.s64 	%rd38, %rd15, 63;
	shr.u64 	%rd39, %rd38, 62;
	add.s64 	%rd40, %rd15, %rd39;
	shr.u64 	%rd41, %rd40, 2;
	cvt.u32.u64 	%r43, %rd41;
	// begin inline asm
	nanosleep.u32 %r43;
	// end inline asm
	bra.uni 	$L__BB0_15;

$L__BB0_20:
	mov.u32 	%r42, 1000000;
	// begin inline asm
	nanosleep.u32 %r42;
	// end inline asm
	bra.uni 	$L__BB0_15;

$L__BB0_16:
	add.s64 	%rd47, %rd47, 1;
	setp.lt.u64 	%p10, %rd47, %rd5;
	@%p10 bra 	$L__BB0_4;

$L__BB0_17:
	ret;

}

